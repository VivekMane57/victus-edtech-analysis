{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb7fd15",
   "metadata": {},
   "source": [
    "# 01 â€” Preprocessing (merge, impute, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c173ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this if your data isn't under ./data\n",
    "base_path = r\"D:\\IITB\\STData\\1\"\n",
    "  # or keep \"./data\" if you copy CSVs there\n",
    "\n",
    "# Because this notebook runs from repo/notebooks/, save relative to repo root:\n",
    "save_models_to = r\"../models\"        # goes to repo/models/\n",
    "save_fig_to    = r\"./figures\"        # goes to repo/notebooks/figures/\n",
    "\n",
    "import os, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "os.makedirs(save_models_to, exist_ok=True)\n",
    "os.makedirs(save_fig_to,    exist_ok=True)\n",
    "\n",
    "def read_csv(name):\n",
    "    p = os.path.join(base_path, name)\n",
    "    return pd.read_csv(p)\n",
    "\n",
    "print(\"Using base_path:\", base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9310d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 01 â€” Preprocessing (FULL)\n",
    "# =========================\n",
    "# Paths (adjust ONLY if your files are elsewhere)\n",
    "base_path    = r\"D:\\IITB\\STData\\1\"   # <- your subject-1 folder with 1_EYE.csv etc.\n",
    "save_models  = r\"../models\"          # notebook is in repo/notebooks, so ../models is repo/models\n",
    "save_figures = r\"./figures\"          # figures go to repo/notebooks/figures\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pandas import merge_asof\n",
    "from scipy.signal import spectrogram\n",
    "\n",
    "os.makedirs(save_models,  exist_ok=True)\n",
    "os.makedirs(save_figures, exist_ok=True)\n",
    "print(\"Using base_path:\", base_path)\n",
    "\n",
    "# -------------------------\n",
    "# 1) Load raw modalities\n",
    "# -------------------------\n",
    "def must_read(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "eye  = must_read(os.path.join(base_path, \"1_EYE.csv\"))\n",
    "eeg  = must_read(os.path.join(base_path, \"1_EEG.csv\"))\n",
    "gsr  = must_read(os.path.join(base_path, \"1_GSR.csv\"))\n",
    "tiva = must_read(os.path.join(base_path, \"1_TIVA.csv\"))\n",
    "psy  = pd.read_csv(os.path.join(base_path, \"1_PSY.csv\"))  if os.path.exists(os.path.join(base_path,\"1_PSY.csv\"))  else None\n",
    "ivt  = pd.read_csv(os.path.join(base_path, \"1_IVT.csv\"))  if os.path.exists(os.path.join(base_path,\"1_IVT.csv\"))  else None\n",
    "\n",
    "print(\"Loaded shapes:\", {k:v.shape for k,v in {\n",
    "    \"EYE\":eye, \"EEG\":eeg, \"GSR\":gsr, \"TIVA\":tiva, \"PSY\":psy, \"IVT\":ivt}.items() if v is not None})\n",
    "\n",
    "# -------------------------\n",
    "# 2) Helpers\n",
    "# -------------------------\n",
    "def tcol(df):\n",
    "    \"\"\"Pick a time column that exists in the given dataframe.\"\"\"\n",
    "    for c in [\"UnixTime\",\"TimeStamp\",\"Timestamp\",\"routineStamp\",\"time\",\"Time\",\"Unix Time\",\"Unix_Timestamp\"]:\n",
    "        if c in df.columns: return c\n",
    "    # fallback: first numeric col\n",
    "    for c in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[c]): return c\n",
    "    raise KeyError(\"No time-like column found\")\n",
    "\n",
    "def merge_nearest(a, b, tol=0.5):\n",
    "    \"\"\"Nearest-time merge with tolerance in seconds.\"\"\"\n",
    "    if a is None: return b\n",
    "    if b is None: return a\n",
    "    return merge_asof(a.sort_values(\"Time\"), b.sort_values(\"Time\"),\n",
    "                      on=\"Time\", direction=\"nearest\", tolerance=tol)\n",
    "\n",
    "# -------------------------\n",
    "# 3) Engineer condensed features\n",
    "# -------------------------\n",
    "# EYE -> PupilDiameter\n",
    "eye_t = tcol(eye)\n",
    "pupil_cols = [c for c in [\"ET_PupilLeft\",\"ET_PupilRight\",\"PupilLeft\",\"PupilRight\",\"PupilDiameter\"] if c in eye.columns]\n",
    "if not pupil_cols:\n",
    "    raise KeyError(\"No pupil columns found in 1_EYE.csv; update 'pupil_cols' list above.\")\n",
    "eye_small = eye[[eye_t] + pupil_cols].copy()\n",
    "eye_small[\"PupilDiameter\"] = eye_small[pupil_cols].mean(axis=1, skipna=True)\n",
    "eye_small = eye_small.rename(columns={eye_t:\"Time\"})[[\"Time\",\"PupilDiameter\"]]\n",
    "\n",
    "# EEG -> BetaPower (fallback to other band powers if needed)\n",
    "eeg_t = tcol(eeg)\n",
    "beta_cols = [c for c in eeg.columns if c.lower().startswith(\"beta_\") or c.lower()==\"beta\"]\n",
    "if not beta_cols:\n",
    "    alt_prefixes = [\"delta_\",\"theta_\",\"alpha_\",\"gamma_\"]\n",
    "    beta_cols = [c for c in eeg.columns if any(c.lower().startswith(p) for p in alt_prefixes)]\n",
    "eeg_small = eeg[[eeg_t] + beta_cols].copy() if beta_cols else eeg[[eeg_t]].copy()\n",
    "eeg_small[\"BetaPower\"] = eeg_small[beta_cols].mean(axis=1, skipna=True) if beta_cols else np.nan\n",
    "eeg_small = eeg_small.rename(columns={eeg_t:\"Time\"})[[\"Time\",\"BetaPower\"]]\n",
    "\n",
    "# GSR -> GSR conductance\n",
    "gsr_t = tcol(gsr)\n",
    "gsr_candidates = [c for c in gsr.columns\n",
    "                  if ((\"gsr\" in c.lower()) or (\"eda\" in c.lower()))\n",
    "                  and any(k in c.lower() for k in [\"conduct\", \"micro\", \"skin\"])]\n",
    "if not gsr_candidates:\n",
    "    # fallback: first numeric signal column\n",
    "    gsr_candidates = [c for c in gsr.columns if pd.api.types.is_numeric_dtype(gsr[c]) and c != gsr_t]\n",
    "use_gsr = gsr_candidates[0]\n",
    "gsr_small = gsr[[gsr_t, use_gsr]].rename(columns={gsr_t:\"Time\", use_gsr:\"GSR\"})\n",
    "\n",
    "# TIVA -> EmotionAvg (+Valence/Arousal/Blink if present)\n",
    "tiva_t = tcol(tiva)\n",
    "cols = tiva.columns\n",
    "val   = next((c for c in cols if \"valence\" in c.lower() or c.lower()==\"val\"), None)\n",
    "aro   = next((c for c in cols if \"arousal\" in c.lower() or c.lower()==\"aro\"), None)\n",
    "blink = next((c for c in cols if \"blink\"   in c.lower()), None)\n",
    "emo_words = [\"joy\",\"anger\",\"sad\",\"fear\",\"disgust\",\"surprise\",\"neutral\",\"happy\",\"contempt\"]\n",
    "emo_cols  = [c for c in cols if any(w in c.lower() for w in emo_words)]\n",
    "\n",
    "keep = [tiva_t] + ([val] if val else []) + ([aro] if aro else []) + ([blink] if blink else []) + emo_cols[:10]\n",
    "tiva_small = tiva[keep].rename(columns={tiva_t:\"Time\"})\n",
    "if emo_cols:\n",
    "    tiva_small[\"EmotionAvg\"] = tiva_small[emo_cols].mean(axis=1, skipna=True)\n",
    "elif val and aro:\n",
    "    v = tiva_small[val]; a = tiva_small[aro]\n",
    "    v01 = (v - v.min())/(v.max()-v.min()+1e-9)\n",
    "    a01 = (a - a.min())/(a.max()-a.min()+1e-9)\n",
    "    tiva_small[\"EmotionAvg\"] = (v01 + a01)/2\n",
    "if val:   tiva_small = tiva_small.rename(columns={val:\"Valence\"})\n",
    "if aro:   tiva_small = tiva_small.rename(columns={aro:\"Arousal\"})\n",
    "if blink: tiva_small = tiva_small.rename(columns={blink:\"BlinkRate\"})\n",
    "\n",
    "# -------------------------\n",
    "# 4) Merge all on Time\n",
    "# -------------------------\n",
    "data = None\n",
    "for df in [eye_small, eeg_small, gsr_small, tiva_small]:\n",
    "    data = merge_nearest(data, df, tol=0.5)  # increase tol if needed (e.g., 1.0)\n",
    "\n",
    "if data is None or data.empty:\n",
    "    raise RuntimeError(\"Merged data is empty â€” check time columns or increase tolerance.\")\n",
    "\n",
    "# Engagement proxy if missing\n",
    "if \"Engagement\" not in data.columns:\n",
    "    if \"BlinkRate\" in data.columns:\n",
    "        br = data[\"BlinkRate\"].astype(float)\n",
    "        data[\"Engagement\"] = -(br - np.nanmean(br)) / (np.nanstd(br) + 1e-6)\n",
    "    elif \"GSR\" in data.columns:\n",
    "        g = data[\"GSR\"].astype(float)\n",
    "        data[\"Engagement\"] = 1 - (g - np.nanmin(g)) / (np.nanmax(g) - np.nanmin(g) + 1e-9)\n",
    "    else:\n",
    "        data[\"Engagement\"] = np.nan\n",
    "\n",
    "# -------------------------\n",
    "# 5) Save processed dataset\n",
    "# -------------------------\n",
    "out_csv = os.path.join(base_path, \"processed_merged.csv\")\n",
    "data.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv)\n",
    "display(data.head())\n",
    "\n",
    "# -------------------------\n",
    "# 6) Quick plots\n",
    "# -------------------------\n",
    "def plot_line(x, y, title, fname, ylabel=None):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(x, y)\n",
    "    plt.title(title); plt.xlabel(\"Time\"); plt.ylabel(ylabel or title)\n",
    "    plt.tight_layout()\n",
    "    path = os.path.join(save_figures, fname)\n",
    "    plt.savefig(path); plt.show()\n",
    "    print(\"Figure saved:\", path)\n",
    "\n",
    "t = data[\"Time\"].astype(float).values\n",
    "if \"PupilDiameter\" in data.columns:\n",
    "    plot_line(t, data[\"PupilDiameter\"].astype(float).values, \"Pupil Diameter\", \"01_pupil.png\", \"Pupil\")\n",
    "if \"BetaPower\" in data.columns:\n",
    "    plot_line(t, data[\"BetaPower\"].astype(float).values, \"Beta Power\", \"01_beta.png\", \"Beta Power\")\n",
    "    # Spectrogram (optional)\n",
    "    valid = np.isfinite(t)\n",
    "    dt = np.median(np.diff(t[valid])) if valid.sum()>1 else None\n",
    "    fs = 1.0/dt if (dt and dt>0) else 128.0\n",
    "    f, ts, Sxx = spectrogram(np.nan_to_num(data[\"BetaPower\"].astype(float).values), fs)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.pcolormesh(ts, f, 10*np.log10(Sxx + 1e-12), shading=\"gouraud\")\n",
    "    plt.ylabel(\"Frequency [Hz]\"); plt.xlabel(\"Time [s]\"); plt.title(\"EEG Beta Power Spectrogram\")\n",
    "    plt.colorbar(label=\"Power (dB)\"); plt.tight_layout()\n",
    "    sp = os.path.join(save_figures, \"01_beta_spectrogram.png\")\n",
    "    plt.savefig(sp); plt.show(); print(\"Figure saved:\", sp)\n",
    "if \"EmotionAvg\" in data.columns and data[\"EmotionAvg\"].notna().sum() >= 400:\n",
    "    seq = data[\"EmotionAvg\"].dropna().values[:400]\n",
    "    mat = seq.reshape(20,20)\n",
    "    plt.figure(figsize=(5,4)); plt.imshow(mat, aspect=\"auto\")\n",
    "    plt.title(\"Emotion Intensity Heatmap (Time Slices)\")\n",
    "    plt.colorbar(); plt.tight_layout()\n",
    "    eh = os.path.join(save_figures, \"01_emotion_heatmap.png\")\n",
    "    plt.savefig(eh); plt.show(); print(\"Figure saved:\", eh)\n",
    "# Correlation\n",
    "cols = [c for c in [\"PupilDiameter\",\"EmotionAvg\",\"Engagement\",\"Valence\",\"BetaPower\",\"GSR\"] if c in data.columns]\n",
    "if len(cols) >= 2:\n",
    "    C = data[cols].astype(float).corr()\n",
    "    plt.figure(figsize=(5,4)); plt.imshow(C, cmap=\"viridis\")\n",
    "    plt.xticks(range(len(cols)), cols, rotation=45, ha='right'); plt.yticks(range(len(cols)), cols)\n",
    "    for i in range(len(cols)):\n",
    "        for j in range(len(cols)):\n",
    "            plt.text(j, i, f\"{C.iloc[i,j]:.2f}\", ha='center', va='center', color='w')\n",
    "    plt.title(\"Multimodal Signal Correlation\"); plt.tight_layout()\n",
    "    ch = os.path.join(save_figures, \"01_correlation.png\")\n",
    "    plt.savefig(ch); plt.show(); print(\"Figure saved:\", ch)\n",
    "\n",
    "print(\"âœ… Preprocessing completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

