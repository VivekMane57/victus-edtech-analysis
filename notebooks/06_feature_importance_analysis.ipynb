{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98359aba",
   "metadata": {},
   "source": [
    "# 06 â€” Model-driven Feature Importance (XGBoost + SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c173ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Update this if your data isn't under ./data\n",
    "base_path = r\"D:\\IITB\\STData\\1\"\n",
    "  # change to r\"D:\\IITB\\STData\" on Windows if needed\n",
    "save_models_to = r\"./models\"\n",
    "save_fig_to = r\"./notebooks/figures\"\n",
    "\n",
    "import os, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "os.makedirs(save_models_to, exist_ok=True)\n",
    "os.makedirs(save_fig_to, exist_ok=True)\n",
    "\n",
    "def read_csv(name):\n",
    "    p = os.path.join(base_path, name)\n",
    "    return pd.read_csv(p)\n",
    "\n",
    "print(\"Using base_path:\", base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aee0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade shap xgboost numpy scipy scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e5467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89401056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= ROBUST BINARY LABEL BUILDER (drop-in) =========\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "def _has_two_classes(s: pd.Series) -> bool:\n",
    "    vc = s.value_counts(dropna=True)\n",
    "    return (vc.get(0,0) > 0) and (vc.get(1,0) > 0)\n",
    "\n",
    "def _outer_tail_split(s: pd.Series, quant_pairs=None, min_total=30, min_each=10):\n",
    "    if quant_pairs is None:\n",
    "        quant_pairs = [(0.20,0.80),(0.25,0.75),(0.30,0.70),(0.35,0.65),(0.40,0.60)]\n",
    "    s = pd.to_numeric(s, errors=\"coerce\").replace([np.inf,-np.inf], np.nan)\n",
    "    for lo_q, hi_q in quant_pairs:\n",
    "        lo, hi = s.quantile(lo_q), s.quantile(hi_q)\n",
    "        low_mask  = s <= lo\n",
    "        high_mask = s >= hi\n",
    "        keep_mask = (low_mask | high_mask) & s.notna()\n",
    "        if keep_mask.sum() >= min_total and low_mask.sum() >= min_each and high_mask.sum() >= min_each:\n",
    "            y = pd.Series(0, index=s.index, dtype=int)\n",
    "            y.loc[high_mask] = 1\n",
    "            return y.where(keep_mask, other=np.nan).dropna()\n",
    "    # fallback: median split\n",
    "    med = s.median()\n",
    "    y = (s > med).astype(int)\n",
    "    return y\n",
    "\n",
    "def build_binary_labels(df_raw: pd.DataFrame, X_aligned: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Returns X_use, y_use, source_info\n",
    "    \"\"\"\n",
    "    # clean\n",
    "    Xn = X_aligned.replace([np.inf,-np.inf], np.nan).dropna(axis=1, how=\"all\")\n",
    "\n",
    "    # --- Strategy A: Correct or Engagement column\n",
    "    if \"Correct\" in df_raw.columns:\n",
    "        s = (df_raw[\"Correct\"] > 0).astype(int).iloc[:len(Xn)].reset_index(drop=True)\n",
    "        if _has_two_classes(s):\n",
    "            return Xn.reset_index(drop=True), s, \"A: Correct>0\"\n",
    "    if \"Engagement\" in df_raw.columns:\n",
    "        s = pd.to_numeric(df_raw[\"Engagement\"], errors=\"coerce\").iloc[:len(Xn)].reset_index(drop=True)\n",
    "        y = _outer_tail_split(s)\n",
    "        if len(y) == len(s) and _has_two_classes(y):\n",
    "            return Xn.reset_index(drop=True), y.reset_index(drop=True), \"A: Engagement (quantile/median)\"\n",
    "\n",
    "    # --- Strategy B: Proxy features\n",
    "    proxies = [\"Engagement\",\"BlinkRate\",\"GSR\",\"PupilDiameter\",\"FixationDuration\",\"SaccadeAmplitude\",\"EmotionAvg\",\"BetaPower\"]\n",
    "    avail = [c for c in proxies if c in Xn.columns]\n",
    "    for col in avail:\n",
    "        y = _outer_tail_split(Xn[col])\n",
    "        if len(y) == len(Xn) and _has_two_classes(y):\n",
    "            return Xn.reset_index(drop=True), y.reset_index(drop=True), f\"B: {col}\"\n",
    "\n",
    "    # --- Strategy C: Composite z-score\n",
    "    if avail:\n",
    "        Z = []\n",
    "        for col in avail:\n",
    "            s = pd.to_numeric(Xn[col], errors=\"coerce\")\n",
    "            z = (s - s.mean()) / (s.std(ddof=0) + 1e-9)\n",
    "            Z.append(z)\n",
    "        comp = pd.concat(Z, axis=1).mean(axis=1)\n",
    "        y = _outer_tail_split(comp)\n",
    "        if len(y) == len(Xn) and _has_two_classes(y):\n",
    "            return Xn.reset_index(drop=True), y.reset_index(drop=True), f\"C: composite({'+'.join(avail)})\"\n",
    "\n",
    "    # --- Strategy D: KMeans(2) pseudo-labels\n",
    "    num_cols = [c for c in Xn.columns if np.issubdtype(Xn[c].dtype, np.number)]\n",
    "    Xk = Xn[num_cols].copy()\n",
    "    Xk = Xk.loc[:, Xk.notna().any(axis=0)]      # âœ… FIXED\n",
    "    Xk = Xk.loc[:, Xk.nunique(dropna=True) > 1]\n",
    "    if Xk.shape[1] >= 2:\n",
    "        Z = StandardScaler().fit_transform(Xk.fillna(0.0))\n",
    "        km = KMeans(n_clusters=2, n_init=10, random_state=42)\n",
    "        labels = pd.Series(km.fit_predict(Z), index=Xk.index, dtype=int)\n",
    "        if _has_two_classes(labels):\n",
    "            return Xn.reset_index(drop=True), labels.reset_index(drop=True), \"D: KMeans(2) pseudo-labels\"\n",
    "\n",
    "    raise ValueError(\"Could not create 2-class labels with any strategy; skip this subject.\")\n",
    "\n",
    "# -------- Usage --------\n",
    "X_use, y_use, label_source = build_binary_labels(df_raw, X)\n",
    "print(\"Label source:\", label_source)\n",
    "print(\"Class counts:\", y_use.value_counts().to_dict())\n",
    "print(\"X_use shape:\", X_use.shape)\n",
    "\n",
    "# --- Train XGB ---\n",
    "clf = XGBClassifier(\n",
    "    n_estimators=200, max_depth=3, learning_rate=0.1,\n",
    "    subsample=0.9, colsample_bytree=0.9, n_jobs=-1, eval_metric=\"logloss\"\n",
    ")\n",
    "scores = cross_val_score(clf, X_use.values, y_use.values, cv=3)\n",
    "print(\"XGB CV accuracy:\", round(scores.mean(), 3))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_use.values, y_use.values, test_size=0.2, random_state=42, stratify=y_use.values\n",
    ")\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06 â€” Feature Importance Analysis\n",
    "import os, pandas as pd, numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "FEATURE_CSV = r\"D:\\IITB\\STData\\eye_features_all_students.csv\"\n",
    "\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "os.makedirs(\"./notebooks/figures\", exist_ok=True)\n",
    "\n",
    "print(\"Using:\", FEATURE_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd\n",
    "\n",
    "feat = pd.read_csv(FEATURE_CSV)\n",
    "\n",
    "# Keep numeric features only\n",
    "cols = [c for c in feat.columns if c not in [\"student_id\",\"subject\",\"student\",\"id\"]]\n",
    "X = feat[cols].copy()\n",
    "X = X.loc[:, X.notna().any(axis=0)]\n",
    "X = X.loc[:, X.nunique(dropna=True) > 1]\n",
    "\n",
    "# Labels: if you have true labels, load them here.\n",
    "labels_path = \"./notebooks/figures/04_labels_from_lda.csv\"\n",
    "if os.path.exists(labels_path):\n",
    "    labels_df = pd.read_csv(labels_path)\n",
    "    labels_df[\"student_id\"] = labels_df[\"student_id\"].astype(int)\n",
    "    feat[\"student_id\"] = feat[\"student_id\"].astype(int)\n",
    "    df = feat.merge(labels_df, on=\"student_id\", how=\"inner\")\n",
    "    X = df[cols]\n",
    "    y = df[\"label\"].astype(int).values\n",
    "else:\n",
    "    # Fallback: proxy labels\n",
    "    preferred = [\"PupilDiameter_mean\",\"FixationDuration_mean\",\"SaccadeAmplitude_mean\"]\n",
    "    proxy_col = next((c for c in preferred if c in feat.columns), None)\n",
    "\n",
    "    if proxy_col is None:\n",
    "        # just take the first numeric feature as a proxy\n",
    "        numeric_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "        if not numeric_cols:\n",
    "            raise KeyError(\"âš ï¸ No numeric feature found in features CSV â€” cannot create proxy labels.\")\n",
    "        proxy_col = numeric_cols[0]   # pick the first numeric column\n",
    "        print(f\"âš ï¸ Using first numeric column {proxy_col} as proxy label (median split).\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Using proxy labels from {proxy_col} (median split).\")\n",
    "\n",
    "    m = feat[proxy_col].median()\n",
    "    y = (feat[proxy_col] > m).astype(int).values\n",
    "\n",
    "print(\"Feature shape:\", X.shape, \"| Labels:\", len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0db2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Save model\n",
    "joblib.dump(rf, \"./models/rf_importance.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2699e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"importance\": rf.feature_importances_\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(imp.head(10))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.barh(imp[\"feature\"][:15][::-1], imp[\"importance\"][:15][::-1])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"RandomForest Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./notebooks/figures/06_rf_importances.png\", dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69ad7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = permutation_importance(rf, X_test, y_test, n_repeats=20, random_state=42)\n",
    "\n",
    "pimp = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"importance_mean\": perm.importances_mean,\n",
    "    \"importance_std\": perm.importances_std\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "print(pimp.head(10))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.barh(pimp[\"feature\"][:15][::-1], pimp[\"importance_mean\"][:15][::-1],\n",
    "         xerr=pimp[\"importance_std\"][:15][::-1])\n",
    "plt.xlabel(\"Permutation Importance (mean Â± std)\")\n",
    "plt.title(\"Permutation Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./notebooks/figures/06_perm_importances.png\", dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === XGB train + save artifacts ===\n",
    "import os, json, joblib\n",
    "import numpy as np, pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assume you already have:\n",
    "# - base_path (e.g., r\"D:\\IITB\\STData\\1\")\n",
    "# - df_raw (loaded raw merged file)\n",
    "# - X (processed_clean.csv aligned to raw)\n",
    "# - the function build_binary_labels(df_raw, X) from earlier, returning (X_use, y_use, label_source)\n",
    "\n",
    "models_dir = os.path.join(\"models\")\n",
    "fig_dir    = os.path.join(\"notebooks\", \"figures\")\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "# build labels robustly\n",
    "X_use, y_use, label_source = build_binary_labels(df_raw, X)\n",
    "print(\"Label source:\", label_source)\n",
    "print(\"Class counts:\", y_use.value_counts().to_dict())\n",
    "print(\"X_use shape:\", X_use.shape)\n",
    "\n",
    "# Train / CV\n",
    "clf = XGBClassifier(\n",
    "    n_estimators=300, max_depth=4, learning_rate=0.08,\n",
    "    subsample=0.9, colsample_bytree=0.9, n_jobs=-1, eval_metric=\"logloss\", random_state=42\n",
    ")\n",
    "\n",
    "cv = cross_val_score(clf, X_use.values, y_use.values, cv=3)\n",
    "print(\"XGB CV accuracy:\", round(cv.mean(), 3))\n",
    "\n",
    "# Holdout split for a reportable confusion matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "(train_idx, test_idx) = next(sss.split(X_use, y_use))\n",
    "\n",
    "X_train, X_test = X_use.iloc[train_idx], X_use.iloc[test_idx]\n",
    "y_train, y_test = y_use.iloc[train_idx], y_use.iloc[test_idx]\n",
    "\n",
    "clf.fit(X_train.values, y_train.values)\n",
    "y_pred = clf.predict(X_test.values)\n",
    "\n",
    "# Save model\n",
    "xgb_path = os.path.join(models_dir, \"xgb_model.pkl\")\n",
    "joblib.dump(clf, xgb_path)\n",
    "print(\"Saved model:\", xgb_path)\n",
    "\n",
    "# Save feature importance CSV\n",
    "imp = pd.Series(clf.feature_importances_, index=X_use.columns).sort_values(ascending=False)\n",
    "imp_path = os.path.join(base_path if 'base_path' in globals() else '.', \"xgb_feature_importance.csv\")\n",
    "imp.to_csv(imp_path)\n",
    "print(\"Saved feature importances:\", imp_path)\n",
    "\n",
    "# Save label-source log (so you know later how labels were made)\n",
    "log_path = os.path.join(models_dir, \"label_source.json\")\n",
    "with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"label_source\": label_source}, f, indent=2)\n",
    "print(\"Saved label source:\", log_path)\n",
    "\n",
    "# Confusion matrix + report (saved as PNG + TXT)\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "disp.plot(ax=ax, colorbar=False)\n",
    "plt.title(\"XGB Confusion Matrix (holdout)\")\n",
    "cm_path = os.path.join(fig_dir, \"06_xgb_confusion_matrix.png\")\n",
    "plt.tight_layout(); plt.savefig(cm_path, dpi=150); plt.show()\n",
    "print(\"Saved:\", cm_path)\n",
    "\n",
    "rep = classification_report(y_test, y_pred, digits=3)\n",
    "rep_path = os.path.join(fig_dir, \"06_xgb_classification_report.txt\")\n",
    "with open(rep_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(rep)\n",
    "print(\"Saved:\", rep_path)\n",
    "\n",
    "# Optional: quick bar plot of top-20 features\n",
    "topk = imp.head(20)\n",
    "plt.figure(figsize=(6,5))\n",
    "topk[::-1].plot(kind=\"barh\")  # reverse for top at top\n",
    "plt.title(\"Top-20 Feature Importances (XGB)\")\n",
    "plt.tight_layout()\n",
    "fi_path = os.path.join(fig_dir, \"06_xgb_feature_importance_top20.png\")\n",
    "plt.savefig(fi_path, dpi=150)\n",
    "plt.show()\n",
    "print(\"Saved:\", fi_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e66cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Optional SHAP summary (skip if slow) ===\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    expl = shap.Explainer(clf, X_train)\n",
    "    sv = expl(X_test)\n",
    "    shap.summary_plot(sv.values, X_test, show=False)\n",
    "    shap_path = os.path.join(fig_dir, \"06_shap_summary.png\")\n",
    "    plt.savefig(shap_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"Saved:\", shap_path)\n",
    "except Exception as e:\n",
    "    print(\"SHAP skipped:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

