{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc7deff7",
   "metadata": {},
   "source": [
    "# 04 — LDA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c173ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Update this if your data isn't under ./data\n",
    "base_path = r\"D:\\IITB\\STData\\1\"\n",
    " # change to r\"D:\\IITB\\STData\" on Windows if needed\n",
    "save_models_to = r\"./models\"\n",
    "save_fig_to = r\"./notebooks/figures\"\n",
    "\n",
    "import os, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "os.makedirs(save_models_to, exist_ok=True)\n",
    "os.makedirs(save_fig_to, exist_ok=True)\n",
    "\n",
    "def read_csv(name):\n",
    "    p = os.path.join(base_path, name)\n",
    "    return pd.read_csv(p)\n",
    "\n",
    "print(\"Using base_path:\", base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4c4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, pandas as pd, numpy as np, pickle\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = pd.read_csv(os.path.join(base_path,\"processed_clean.csv\"))\n",
    "# Build a Y label if available; fallback to median split on Engagement\n",
    "df_raw = pd.read_csv(os.path.join(base_path,\"processed_merged.csv\"))\n",
    "if 'Correct' in df_raw.columns:\n",
    "    y = (df_raw['Correct']>0).astype(int).values\n",
    "else:\n",
    "    y = (df_raw['Engagement'] > df_raw['Engagement'].median()).astype(int).values\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "scores = cross_val_score(lda, X.values, y, cv=5)\n",
    "print(\"LDA CV accuracy:\", scores.mean().round(3))\n",
    "\n",
    "lda.fit(X.values, y)\n",
    "coef = pd.Series(lda.coef_[0], index=X.columns).sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "coef.head(20).to_csv(os.path.join(base_path,\"lda_top_features.csv\"), index=True)\n",
    "\n",
    "with open(os.path.join(save_models_to,\"lda_model.pkl\"),\"wb\") as f:\n",
    "    pickle.dump(lda, f)\n",
    "print(\"Saved LDA model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f198bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-CELL: robust labels + LDA using your column names (pupil_mean, fix_mean, sac_mean, …)\n",
    "import os, glob, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "BASE = r\"D:\\IITB\\STData\"\n",
    "FEATURE_CSV = os.path.join(BASE, \"eye_features_all_students.csv\")\n",
    "LABELS_CSV  = os.path.join(BASE, \"labels.csv\")  # optional; if not present we derive\n",
    "\n",
    "def try_read_csv(p):\n",
    "    try:\n",
    "        return pd.read_csv(p)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def ensure_student_id_col(df, df_name=\"df\"):\n",
    "    if df is None or df.empty:\n",
    "        return df\n",
    "    cols = list(df.columns)\n",
    "    if \"student_id\" in cols:\n",
    "        df[\"student_id\"] = pd.to_numeric(df[\"student_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        df = df.dropna(subset=[\"student_id\"]).copy()\n",
    "        df[\"student_id\"] = df[\"student_id\"].astype(int)\n",
    "        return df\n",
    "    for cand in [\"subject\",\"Subject\",\"student\",\"Unnamed: 0\", cols[0]]:\n",
    "        if cand in cols:\n",
    "            df = df.rename(columns={cand: \"student_id\"})\n",
    "            df[\"student_id\"] = pd.to_numeric(df[\"student_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "            df = df.dropna(subset=[\"student_id\"]).copy()\n",
    "            df[\"student_id\"] = df[\"student_id\"].astype(int)\n",
    "            return df\n",
    "    raise KeyError(f\"{df_name}: could not determine 'student_id' column from columns={cols}\")\n",
    "\n",
    "def derive_labels_from_subject_folders(base_dir):\n",
    "    rows = []\n",
    "    for sp in sorted(glob.glob(os.path.join(base_dir, \"*\"))):\n",
    "        if not os.path.isdir(sp): \n",
    "            continue\n",
    "        sid = os.path.basename(sp)\n",
    "        if not sid.isdigit():\n",
    "            continue\n",
    "        sid_i = int(sid)\n",
    "        psy = try_read_csv(os.path.join(sp, f\"{sid}_PSY.csv\"))\n",
    "        eng = try_read_csv(os.path.join(sp, f\"{sid}_ENG.csv\"))\n",
    "        label = None\n",
    "        if psy is not None and \"Correct\" in psy.columns:\n",
    "            label = int((pd.to_numeric(psy[\"Correct\"], errors=\"coerce\").fillna(0) > 0).mean() >= 0.5)\n",
    "        elif eng is not None and \"Engagement\" in eng.columns:\n",
    "            s = pd.to_numeric(eng[\"Engagement\"], errors=\"coerce\")\n",
    "            label = int((s > s.median()).mean() >= 0.5)\n",
    "        if label is not None:\n",
    "            rows.append({\"student_id\": sid_i, \"label\": int(label)})\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"student_id\",\"label\"])\n",
    "    return pd.DataFrame(rows).drop_duplicates(\"student_id\")\n",
    "\n",
    "# 1) Load features\n",
    "feat = try_read_csv(FEATURE_CSV)\n",
    "if feat is None or feat.empty:\n",
    "    raise FileNotFoundError(f\"Could not read features from {FEATURE_CSV}\")\n",
    "feat = ensure_student_id_col(feat, \"features\")\n",
    "for c in feat.columns:\n",
    "    if c != \"student_id\":\n",
    "        feat[c] = pd.to_numeric(feat[c], errors=\"coerce\")\n",
    "\n",
    "print(\"Feature columns:\", feat.columns.tolist())\n",
    "\n",
    "# 2) Get/derive labels\n",
    "labels_df = None\n",
    "if os.path.exists(LABELS_CSV):\n",
    "    labels_df = try_read_csv(LABELS_CSV)\n",
    "    if labels_df is not None and not labels_df.empty:\n",
    "        labels_df = ensure_student_id_col(labels_df, \"labels_csv\")\n",
    "        if \"label\" not in labels_df.columns:\n",
    "            for cand in [\"y\",\"Label\",\"target\",\"class\"]:\n",
    "                if cand in labels_df.columns:\n",
    "                    labels_df = labels_df.rename(columns={cand:\"label\"})\n",
    "                    break\n",
    "        if \"label\" in labels_df.columns:\n",
    "            labels_df[\"label\"] = pd.to_numeric(labels_df[\"label\"], errors=\"coerce\").astype(int)\n",
    "        else:\n",
    "            labels_df = None\n",
    "\n",
    "if labels_df is None or labels_df.empty:\n",
    "    print(\"labels.csv missing/invalid → deriving from PSY/ENG …\")\n",
    "    labels_df = derive_labels_from_subject_folders(BASE)\n",
    "\n",
    "# Fallback: build proxy labels from your feature names\n",
    "if labels_df is None or labels_df.empty:\n",
    "    print(\"No PSY/ENG labels found → creating proxy labels from features (median split).\")\n",
    "    # <—— these match your CSV: pupil_mean, fix_mean, sac_mean (and counts/stds as backups)\n",
    "    proxy_candidates = [\n",
    "        \"pupil_mean\",\n",
    "        \"fix_mean\", \"sac_mean\",\n",
    "        \"fix_count\", \"sac_count\",\n",
    "        \"pupil_std\", \"fix_std\", \"sac_std\",\n",
    "    ]\n",
    "    proxy_col = next((c for c in proxy_candidates if c in feat.columns), None)\n",
    "    if proxy_col is None:\n",
    "        raise KeyError(f\"No suitable proxy feature found. Looked for {proxy_candidates}. \"\n",
    "                       f\"Available: {feat.columns.tolist()}\")\n",
    "    tmp = feat[[\"student_id\", proxy_col]].dropna().copy()\n",
    "    m = tmp[proxy_col].median()\n",
    "    tmp[\"label\"] = (tmp[proxy_col] > m).astype(int)\n",
    "    labels_df = tmp[[\"student_id\",\"label\"]].copy()\n",
    "\n",
    "labels_df = ensure_student_id_col(labels_df, \"labels_final\")\n",
    "labels_df[\"label\"] = pd.to_numeric(labels_df[\"label\"], errors=\"coerce\").astype(int)\n",
    "labels_df = labels_df.dropna(subset=[\"student_id\",\"label\"]).drop_duplicates(\"student_id\")\n",
    "print(\"Label counts:\", labels_df[\"label\"].value_counts().to_dict())\n",
    "\n",
    "# 3) Merge & prepare X, y\n",
    "df = feat.merge(labels_df, on=\"student_id\", how=\"inner\")\n",
    "if df.empty:\n",
    "    raise RuntimeError(\"Merge produced 0 rows. Check overlap between features and labels.\")\n",
    "X = df.drop(columns=[\"student_id\",\"label\"]).select_dtypes(include=[np.number]).copy()\n",
    "y = df[\"label\"].astype(int).values\n",
    "X = X[[c for c in X.columns if X[c].nunique(dropna=True) > 1]]  # drop constants\n",
    "print(\"Merged shape:\", df.shape, \"| Final feature count:\", X.shape[1])\n",
    "\n",
    "# 4) Quick LDA sanity check\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.values, y, test_size=0.25, random_state=42, stratify=y if len(np.unique(y))==2 else None\n",
    ")\n",
    "lda_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"lda\", LinearDiscriminantAnalysis()),\n",
    "])\n",
    "lda_pipe.fit(X_train, y_train)\n",
    "pred = lda_pipe.predict(X_test)\n",
    "print(\"LDA accuracy:\", round(accuracy_score(y_test, pred), 3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, pred))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ab23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save the fitted LDA pipeline ===\n",
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "models_dir = \"../models\"  # notebook is in notebooks/, so ../models is repo/models\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "lda_path = os.path.join(models_dir, \"lda_model.pkl\")\n",
    "dump(lda_pipe, lda_path)\n",
    "\n",
    "print(f\"✅ LDA pipeline saved to: {lda_path}\")\n",
    "\n",
    "\n",
    "from joblib import load\n",
    "_ = load(lda_path)\n",
    "print(\"✅ Loaded OK.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PCA vs LDA comparison ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Make sure X, y exist and contain only numeric columns\n",
    "X_num = X.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# Fit PCA on all features (2D for visualization)\n",
    "pca2 = PCA(n_components=2, random_state=42)\n",
    "Xp = pca2.fit_transform(X_num)\n",
    "\n",
    "# LDA transform to 1D (binary) or 2D (multiclass). Here we’ll plot 1D on x, 0 on y.\n",
    "# Use the same lda_pipe you trained (with imputer+scaler inside).\n",
    "# We need to call transform on the *preprocessed* X: use lda_pipe[:-1] (all steps except last LDA) to get scaled features.\n",
    "pre_X = lda_pipe[:-1].transform(X_num)           # impute + scale\n",
    "Xd_1d = lda_pipe[-1].transform(pre_X)            # LDA -> 1D for 2 classes\n",
    "Xd = np.c_[Xd_1d, np.zeros_like(Xd_1d)]          # stack a zero y to plot on a line\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# PCA scatter\n",
    "axs[0].scatter(Xp[:, 0], Xp[:, 1], c=y, s=40)\n",
    "axs[0].set_title(\"PCA (2D) of student features\")\n",
    "axs[0].set_xlabel(\"PC1\")\n",
    "axs[0].set_ylabel(\"PC2\")\n",
    "\n",
    "# LDA scatter (1D shown as line)\n",
    "axs[1].scatter(Xd[:, 0], Xd[:, 1], c=y, s=40)\n",
    "axs[1].set_title(\"LDA projection (1D shown on x-axis)\")\n",
    "axs[1].set_xlabel(\"LD1\")\n",
    "axs[1].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Explained variance (PCA):\", np.round(pca2.explained_variance_ratio_, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b7de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save PCA (2D) and LDA (1D) projections ===\n",
    "import os, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "exports = \"../notebooks/figures\"\n",
    "os.makedirs(exports, exist_ok=True)\n",
    "\n",
    "# numeric X\n",
    "X_num = X.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# PCA 2D\n",
    "pca2 = PCA(n_components=2, random_state=42)\n",
    "Xp = pca2.fit_transform(X_num)\n",
    "\n",
    "pca_df = pd.DataFrame(Xp, columns=[\"PC1\",\"PC2\"])\n",
    "pca_df[\"label\"] = y\n",
    "pca_df.to_csv(\"../eye_features_pca.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(Xp[:,0], Xp[:,1], c=y, s=40)\n",
    "plt.title(\"PCA (2D) of student features\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(exports,\"04_pca_scatter.png\"), dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# LDA 1D\n",
    "pre_X = lda_pipe[:-1].transform(X_num)      # impute+scale\n",
    "ld1 = lda_pipe[-1].transform(pre_X).ravel() # 1D\n",
    "\n",
    "lda_df = pd.DataFrame({\"LD1\": ld1, \"label\": y})\n",
    "lda_df.to_csv(\"../eye_features_lda1d.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(6,2.8))\n",
    "plt.scatter(ld1, np.zeros_like(ld1), c=y, s=40)\n",
    "plt.title(\"LDA projection (1D)\"); plt.yticks([])\n",
    "plt.xlabel(\"LD1\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(exports,\"04_lda_1d.png\"), dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved:\", \"../eye_features_pca.csv\", \"and\", \"../eye_features_lda1d.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd9b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a445622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save confusion matrix & classification report as files ===\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np, matplotlib.pyplot as plt, os\n",
    "\n",
    "exports = \"../notebooks/figures\"\n",
    "os.makedirs(exports, exist_ok=True)\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cr = classification_report(y_test, pred, digits=3)\n",
    "\n",
    "# Save text\n",
    "with open(\"../lda_classification_report.txt\", \"w\") as f:\n",
    "    f.write(cr)\n",
    "\n",
    "# Plot confusion matrix with matplotlib\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"LDA Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(set(y_test)))\n",
    "plt.xticks(tick_marks, tick_marks)\n",
    "plt.yticks(tick_marks, tick_marks)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "\n",
    "# Add numbers\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"red\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(exports, \"04_lda_confusion.png\"), dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved:\", \"../lda_classification_report.txt\", \"and 04_lda_confusion.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0e749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5-fold CV on the same pipeline ===\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(lda_pipe, X, y, scoring=\"accuracy\", cv=cv)\n",
    "print(\"5-fold CV accuracy:\", np.round(scores, 3), \" | mean:\", scores.mean().round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c23647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LDA coefficients as feature importances ===\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, os\n",
    "\n",
    "# refit on all data to get coefs aligned with lda_pipe's preprocessing\n",
    "lda_pipe.fit(X, y)\n",
    "\n",
    "coef = lda_pipe[-1].coef_.ravel()  # shape (n_features,)\n",
    "names = X.columns.to_list()\n",
    "imp = pd.Series(np.abs(coef), index=names).sort_values(ascending=False)\n",
    "\n",
    "imp.to_csv(\"../lda_feature_importance.csv\", header=[\"abs_coef\"])\n",
    "plt.figure(figsize=(7,4))\n",
    "imp.head(15).iloc[::-1].plot(kind=\"barh\")\n",
    "plt.title(\"LDA | Top features (|coef|)\")\n",
    "plt.tight_layout(); plt.savefig(\"../notebooks/figures/04_lda_feature_importance.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved:\", \"../lda_feature_importance.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aafc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inference: load lda_model.pkl and predict ===\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "\n",
    "lda_loaded = load(\"../models/lda_model.pkl\")\n",
    "\n",
    "# Example: take first 3 students from your existing table (replace with your new rows)\n",
    "sample = X.head(3).copy()\n",
    "pred_labels = lda_loaded.predict(sample)\n",
    "pred_proba  = lda_loaded.predict_proba(sample)[:,1] if hasattr(lda_loaded, \"predict_proba\") else None\n",
    "\n",
    "out = sample.copy()\n",
    "out[\"pred_label\"] = pred_labels\n",
    "if pred_proba is not None:\n",
    "    out[\"pred_prob_1\"] = pred_proba\n",
    "out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
